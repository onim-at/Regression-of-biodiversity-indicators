{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression on biodiversity index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to test different models on our dataset, trying to get a better results using a grid search and the testing the models on a dataset of a different region.\n",
    "\n",
    "For each model we're going to use a RandomizedSearchCV to narrow our parameters research and the the GridSearchCV to find the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "module_this = os.path.abspath(os.path.join(os.getcwd()))\n",
    "modules = [ module_this]\n",
    "\n",
    "for module in modules:\n",
    "    if module not in sys.path:\n",
    "        sys.path.append(module)\n",
    "\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_best_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../Dataset\"\n",
    "regression_label = 'habitat_richness'\n",
    "test_size = 0.2\n",
    "swi_labels = ['SWI1km-SWI-002', 'SWI1km-SWI-100', 'SWI1km-SWI-040', 'SWI1km-SWI-005', \n",
    "              'SWI1km-SWI-010', 'SWI1km-SWI-060', 'SWI1km-SWI-015', 'SWI1km-SWI-020']\n",
    "\n",
    "datas = []\n",
    "\n",
    "paths = [f for f in glob.glob(folder + \"/*.csv\") if 'france' in f]\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path, index_col=['longitude', 'latitude'])\n",
    "\n",
    "    if(df.isna().any().any()):\n",
    "        print(path, '\\t has ', df.isna().any().sum(), ' row with null values')\n",
    "    \n",
    "    y = df[regression_label].values\n",
    "    X = df.drop(columns=[regression_label]).values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, shuffle=True)\n",
    "    datas.append({'name': path[11:-4], 'dataframe': df, 'y': y, 'X': X, \n",
    "                'X_train': X_train, 'X_test': X_test, \n",
    "            'y_train': y_train, 'y_test': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france_out_closest_point_mean_handle_custom_set \t--\t (1882, 47)\n",
      "france_out_knn_handle_custom_set \t--\t (1882, 47)\n",
      "france_out_mean_handle_custom_set \t--\t (1882, 47)\n",
      "france_out_remove_handle_set_null \t--\t (1138, 47)\n",
      "france_yearavg_out_closest_point_mean_handle_custom_set \t--\t (1882, 47)\n",
      "france_yearavg_out_mean_handle_custom_set \t--\t (1882, 47)\n",
      "france_yearavg_out_remove_handle_set_null \t--\t (1138, 47)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(x['name'], \"\\t--\\t\",x['dataframe'].shape) for x in datas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state = 42)\n",
    "scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing datasets with all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "france_out_closest_point_mean_handle_custom_set \t validation score: \t 0.741  +/-  0.019\n",
      "france_out_closest_point_mean_handle_custom_set \t test score: \t\t 0.763\n",
      "--------------------------------------------\n",
      "france_out_knn_handle_custom_set \t validation score: \t 0.733  +/-  0.021\n",
      "france_out_knn_handle_custom_set \t test score: \t\t 0.755\n",
      "--------------------------------------------\n",
      "france_out_mean_handle_custom_set \t validation score: \t 0.740  +/-  0.021\n",
      "france_out_mean_handle_custom_set \t test score: \t\t 0.761\n",
      "--------------------------------------------\n",
      "france_out_remove_handle_set_null \t validation score: \t 0.725  +/-  0.025\n",
      "france_out_remove_handle_set_null \t test score: \t\t 0.735\n",
      "--------------------------------------------\n",
      "france_yearavg_out_closest_point_mean_handle_custom_set \t validation score: \t 0.738  +/-  0.017\n",
      "france_yearavg_out_closest_point_mean_handle_custom_set \t test score: \t\t 0.763\n",
      "--------------------------------------------\n",
      "france_yearavg_out_mean_handle_custom_set \t validation score: \t 0.736  +/-  0.017\n",
      "france_yearavg_out_mean_handle_custom_set \t test score: \t\t 0.764\n",
      "--------------------------------------------\n",
      "france_yearavg_out_remove_handle_set_null \t validation score: \t 0.719  +/-  0.021\n",
      "france_yearavg_out_remove_handle_set_null \t test score: \t\t 0.747\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for data in datas:\n",
    "    rfr = RandomForestRegressor(random_state = 42)\n",
    "    model = make_pipeline(scaler, rfr)\n",
    "    val_score = cross_val_score(model, data['X_train'], data['y_train'], cv=cv, n_jobs=-1, verbose=0)\n",
    "    data['val_score'] = val_score\n",
    "    print(data['name'], \"\\t validation score: \\t\", \"{:.3f}\".format(val_score.mean()), \" +/- \", \"{:.3f}\".format(val_score.std()))\n",
    "    model.fit(data['X_train'], data['y_train'])\n",
    "    #print(model.score(data['X_train'], data['y_train']))\n",
    "    test_score = model.score(data['X_test'], data['y_test'])\n",
    "    print(data['name'], \"\\t test score: \\t\\t\", \"{:.3f}\".format(test_score))\n",
    "    print('--------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfr__n_estimators': [50, 100, 200, 500, 1000],\n",
       " 'rfr__max_features': ['auto', 'sqrt'],\n",
       " 'rfr__max_depth': [50, None],\n",
       " 'rfr__min_samples_split': [2, 5, 10],\n",
       " 'rfr__min_samples_leaf': [1, 2, 4],\n",
       " 'rfr__bootstrap': [True, False]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [50, 100, 200, 500, 1000]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [10, 20, 50, 100, None]\n",
    "max_depth = [50]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "grid_params = {'rfr__n_estimators': n_estimators,\n",
    "               'rfr__max_features': max_features,\n",
    "               'rfr__max_depth': max_depth,\n",
    "               'rfr__min_samples_split': min_samples_split,\n",
    "               'rfr__min_samples_leaf': min_samples_leaf,\n",
    "               'rfr__bootstrap': bootstrap}\n",
    "grid_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 123.9min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 168.7min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 325.9min\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for data in datas:\n",
    "    rfr = RandomForestRegressor()\n",
    "    model = Pipeline([('scaler', scaler), ('rfr', rfr)])\n",
    "\n",
    "    grid_search = GridSearchCV(estimator = model, param_grid = grid_params, \n",
    "                              cv = cv, n_jobs = -1, verbose = 1)\n",
    "    grid_search.fit(data['X_train'], data['y_train'])\n",
    "    print(data['name'], ' cross validation best score: \\t',  \"{:.3f}\".format(grid_search.best_score_))\n",
    "    torch.save(grid_search.best_params_, data['name'] + \"__bset_params\")\n",
    "    data['rfr_best'] = grid_search.best_params_\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_model.fit(data['X_train'], data['y_train'])\n",
    "    test_score = best_model.score(data['X_test'], data['y_test'])\n",
    "    print(data['name'], \"\\t best model test score: \\t\\t\", \"{:.3f}\".format(test_score))\n",
    "    print('--------------------------------------------')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
