{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression using satellite images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiodiversityDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, img_dir, image_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with features.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a image.\n",
    "        \"\"\"\n",
    "        self.features = pd.read_csv(csv_file, index_col=['longitude', 'latitude'])\n",
    "        self.img_dir = img_dir\n",
    "        self.image_transform = image_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(idx[0]) + \"_\" + str(idx[1]) + \".jpg\"\n",
    "        img_path = os.path.join(self.img_dir,\n",
    "                                img_name)\n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "\n",
    "        out = torch.from_numpy(np.array([self.features.loc[idx]['habitat_richness']])).detach().clone().reshape([-1, 1])\n",
    "        features = self.features.drop(columns=['habitat_richness']).loc[idx].values\n",
    "        features = torch.from_numpy(features.astype('float').reshape(-1, 46)).detach().clone()\n",
    "        sample = {'image': image, 'features': features, 'out': out}\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    def get_feature(self):\n",
    "         return torch.from_numpy(self.features.drop(columns=['habitat_richness']).values).detach().clone()\n",
    "    \n",
    "    def get_out(self):\n",
    "        return torch.from_numpy(self.features['habitat_richness'].values).detach().clone().reshape(-1, 1)\n",
    "    \n",
    "    def get_index(self):\n",
    "        return dataset.features.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureImageNet(nn.Module):\n",
    "\n",
    "    def __init__(self, image_net, feature_input_size, output_size, feature_scaler):\n",
    "        super(FeatureImageNet, self).__init__()\n",
    "        self.image_net = image_net\n",
    "        self.feature_scaler = feature_scaler\n",
    "    \n",
    "        self.feat_fc1 = nn.Linear(feature_input_size, 46)  \n",
    "        self.feat_fc2 = nn.Linear(46, 100)\n",
    "        self.feat_fc3 = nn.Linear(100, 128)\n",
    "\n",
    "        self.fc1 = nn.Linear(256, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, images, features):\n",
    "        x_features = self.feature_scaler.transform(features)\n",
    "        x_features = F.relu(self.feat_fc1(x_features))\n",
    "        x_features = F.relu(self.feat_fc2(x_features))\n",
    "        x_features = F.relu(self.feat_fc3(x_features))\n",
    "        \n",
    "        x_image = self.image_net(images)\n",
    "      \n",
    "        x = torch.cat([x_features, x_image] , dim=1, out=None)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTMinMaxScaler():\n",
    "    \"\"\"\n",
    "    Transforms each channel to the range [0, 1].\n",
    "    \"\"\"\n",
    "    def transform(self, tensor):\n",
    "        tensor.mul_(self.scale).sub_(self.subtract)\n",
    "        return tensor.float() \n",
    "    \n",
    "    def fit(self, tensor):\n",
    "        t = tensor.detach().clone()\n",
    "        self.scale = 1.0 / (t.max(dim=0, keepdim=True)[0] - t.min(dim=0, keepdim=True)[0])\n",
    "        self.scale[self.scale == float(\"Inf\")] = 0\n",
    "        t.mul_(self.scale)\n",
    "        self.subtract = t.min(dim=0, keepdim=True)[0]\n",
    "        \n",
    "    def fit_transform(self, tensor):\n",
    "        self.scale = 1.0 / (tensor.max(dim=0, keepdim=True)[0] - tensor.min(dim=0, keepdim=True)[0])\n",
    "        self.scale[self.scale == float(\"Inf\")] = 0\n",
    "        tensor.mul_(self.scale)\n",
    "        self.subtract = tensor.min(dim=0, keepdim=True)[0]\n",
    "        tensor.sub_(self.subtract)\n",
    "        return tensor.float() \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\minoc/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../Dataset/images\"\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "feature_scaler = PyTMinMaxScaler()\n",
    "out_scaler = PyTMinMaxScaler()\n",
    "\n",
    "dataset = BiodiversityDataset(data_dir+\"/test.csv\", data_dir+\"/test\", image_transform)\n",
    "\n",
    "feature_scaler.fit(dataset.get_feature())\n",
    "out_scaler.fit(dataset.get_out())\n",
    "\n",
    "\n",
    "resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
    "resnet.fc = nn.Linear(512, 128)\n",
    "\n",
    "net = FeatureImageNet(image_net=resnet, feature_input_size=46, output_size=1, feature_scaler=feature_scaler)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset, model, optimizer, criterion, epochs=20, print_step=1000):\n",
    "    for epoch in range(epochs): \n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, idx in enumerate(dataset.get_index()):\n",
    "            sample = dataset[idx]\n",
    "            expected_outputs = out_scaler.transform(sample['out'])\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(sample['image'].unsqueeze(0), sample['features'])\n",
    "            loss = criterion(outputs, expected_outputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % print_step == print_step-1:    # print every 500 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / print_step))\n",
    "                running_loss = 0.0\n",
    "    \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     7] loss: 0.560\n",
      "[2,     7] loss: 0.220\n",
      "[3,     7] loss: 0.222\n",
      "[4,     7] loss: 0.199\n",
      "[5,     7] loss: 0.193\n",
      "[6,     7] loss: 0.204\n",
      "[7,     7] loss: 0.180\n",
      "[8,     7] loss: 0.175\n",
      "[9,     7] loss: 0.144\n",
      "[10,     7] loss: 0.147\n",
      "[11,     7] loss: 0.127\n",
      "[12,     7] loss: 0.132\n",
      "[13,     7] loss: 0.118\n",
      "[14,     7] loss: 0.109\n",
      "[15,     7] loss: 0.079\n",
      "[16,     7] loss: 0.084\n",
      "[17,     7] loss: 0.067\n",
      "[18,     7] loss: 0.041\n",
      "[19,     7] loss: 0.037\n",
      "[20,     7] loss: 0.020\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_model(dataset=dataset, model=net, optimizer=optimizer, criterion=criterion, epochs=20, print_step=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(dataset, model):\n",
    "    with torch.no_grad():\n",
    "        expected_outputs = []\n",
    "        outputs = []\n",
    "        for idx in dataset.get_index():\n",
    "            sample = dataset[idx]\n",
    "            expected_outputs += out_scaler.transform(sample['out'])\n",
    "            outputs += net(sample['image'].unsqueeze(0), sample['features'])\n",
    "\n",
    "    print(f\"R2 score: {r2_score(outputs, expected_outputs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(dataset, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
