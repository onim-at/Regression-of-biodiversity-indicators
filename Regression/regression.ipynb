{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression on biodiversity index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to test different models on our dataset, trying to get a better results using a grid search and the testing the models on a dataset of a different region.\n",
    "\n",
    "For each model we're going to use a RandomizedSearchCV to narrow our parameters research and the the GridSearchCV to find the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from itertools import combinations \n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "module_this = os.path.abspath(os.path.join(os.getcwd()))\n",
    "modules = [ module_this]\n",
    "\n",
    "for module in modules:\n",
    "    if module not in sys.path:\n",
    "        sys.path.append(module)\n",
    "\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../Dataset\"\n",
    "regression_label = 'habitat_richness'\n",
    "test_size = 0.2\n",
    "#swi_labels = ['SWI1km-SWI-002', 'SWI1km-SWI-100', 'SWI1km-SWI-040', 'SWI1km-SWI-005', \n",
    "#              'SWI1km-SWI-010', 'SWI1km-SWI-060', 'SWI1km-SWI-015', 'SWI1km-SWI-020']\n",
    "\n",
    "datas = []\n",
    "\n",
    "paths = [f for f in glob.glob(folder + \"/*.csv\") if 'out_closest_point_mean' in f]\n",
    "paths += [f for f in glob.glob(folder + \"/*.csv\") if 'out_knn' in f]\n",
    "paths += [f for f in glob.glob(folder + \"/*.csv\") if 'out_mean' in f]\n",
    "paths += [f for f in glob.glob(folder + \"/*.csv\") if 'out_remove' in f]\n",
    "\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path, index_col=['longitude', 'latitude'])\n",
    "\n",
    "    if(df.isna().any().any()):\n",
    "        print(path, '\\t has ', df.isna().any().sum(), ' row with null values')\n",
    "    \n",
    "    y = df[regression_label].values\n",
    "    X = df.drop(columns=[regression_label]).values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, shuffle=True)\n",
    "    datas.append({'name': path[11:-4], 'dataframe': df, 'y': y, 'X': X, \n",
    "                'X_train': X_train, 'X_test': X_test, \n",
    "            'y_train': y_train, 'y_test': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulgaria_out_closest_point_mean_handle_custom_set \t--\t (14458, 47)\n",
      "finland_out_closest_point_mean_handle_custom_set \t--\t (17714, 47)\n",
      "france_out_closest_point_mean_handle_custom_set \t--\t (1882, 47)\n",
      "italy_out_closest_point_mean_handle_custom_set \t--\t (17387, 47)\n",
      "bulgaria_out_knn_handle_custom_set \t--\t (14458, 47)\n",
      "finland_out_knn_handle_custom_set \t--\t (17714, 47)\n",
      "france_out_knn_handle_custom_set \t--\t (1882, 47)\n",
      "italy_out_knn_handle_custom_set \t--\t (17387, 47)\n",
      "bulgaria_out_mean_handle_custom_set \t--\t (14458, 47)\n",
      "finland_out_mean_handle_custom_set \t--\t (17714, 47)\n",
      "france_out_mean_handle_custom_set \t--\t (1882, 47)\n",
      "italy_out_mean_handle_custom_set \t--\t (17387, 47)\n",
      "bulgaria_out_remove_handle_set_null \t--\t (6842, 47)\n",
      "finland_out_remove_handle_set_null \t--\t (17654, 47)\n",
      "france_out_remove_handle_set_null \t--\t (1138, 47)\n",
      "italy_out_remove_handle_set_null \t--\t (8273, 47)\n"
     ]
    }
   ],
   "source": [
    "for x in datas:\n",
    "    print(x['name'], \"\\t--\\t\",x['dataframe'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_closest_point = np.vstack((datas[0]['X'], datas[1]['X'], datas[2]['X'], datas[3]['X']))\n",
    "y_closest_point = np.concatenate((datas[0]['y'], datas[1]['y'], datas[2]['y'], datas[3]['y']))\n",
    "region_id_closest_point = np.hstack(np.array([[i] * d['X'].shape[0] for i, d in enumerate(datas[0:4])]))\n",
    "\n",
    "X_knn = np.vstack((datas[4]['X'], datas[5]['X'], datas[6]['X'], datas[7]['X']))\n",
    "y_knn = np.concatenate((datas[4]['y'], datas[5]['y'], datas[6]['y'], datas[7]['y']))\n",
    "region_id_knn = np.hstack(np.array([[i] * d['X'].shape[0] for i, d in enumerate(datas[4:8])]))\n",
    "\n",
    "X_mean = np.vstack((datas[8]['X'], datas[9]['X'], datas[10]['X'], datas[11]['X']))\n",
    "y_mean = np.concatenate((datas[8]['y'], datas[9]['y'], datas[10]['y'], datas[11]['y']))\n",
    "region_id_mean = np.hstack(np.array([[i] * d['X'].shape[0] for i, d in enumerate(datas[8:12])]))\n",
    "\n",
    "X_remove = np.vstack((datas[12]['X'], datas[13]['X'], datas[14]['X'], datas[15]['X']))\n",
    "y_remove = np.concatenate((datas[12]['y'], datas[13]['y'], datas[14]['y'], datas[15]['y']))\n",
    "region_id_remove = np.hstack(np.array([[i] * d['X'].shape[0] for i, d in enumerate(datas[12:16])]))\n",
    "\n",
    "\n",
    "Xs = [X_closest_point, X_knn, X_mean, X_remove]\n",
    "ys = [y_closest_point, y_knn, y_mean, y_remove]\n",
    "region_ids = [region_id_closest_point, region_id_knn, region_id_mean, region_id_remove]\n",
    "\n",
    "cv = KFold(n_splits=4, shuffle=True, random_state = 42)\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching the best outliers handler\n",
    "\n",
    "We train a random forest regressor over datasets created with different outlier handling techniques to see which one performs better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regional dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulgaria_out_closest_point_mean_handle_custom_set \t validation score: \t 0.925  +/-  0.005\n",
      "--------------------------------------------\n",
      "finland_out_closest_point_mean_handle_custom_set \t validation score: \t 0.717  +/-  0.011\n",
      "--------------------------------------------\n",
      "france_out_closest_point_mean_handle_custom_set \t validation score: \t 0.742  +/-  0.013\n",
      "--------------------------------------------\n",
      "italy_out_closest_point_mean_handle_custom_set \t validation score: \t 0.835  +/-  0.003\n",
      "--------------------------------------------\n",
      "bulgaria_out_knn_handle_custom_set \t validation score: \t 0.923  +/-  0.005\n",
      "--------------------------------------------\n",
      "finland_out_knn_handle_custom_set \t validation score: \t 0.717  +/-  0.011\n",
      "--------------------------------------------\n",
      "france_out_knn_handle_custom_set \t validation score: \t 0.735  +/-  0.018\n",
      "--------------------------------------------\n",
      "italy_out_knn_handle_custom_set \t validation score: \t 0.827  +/-  0.004\n",
      "--------------------------------------------\n",
      "bulgaria_out_mean_handle_custom_set \t validation score: \t 0.925  +/-  0.005\n",
      "--------------------------------------------\n",
      "finland_out_mean_handle_custom_set \t validation score: \t 0.717  +/-  0.010\n",
      "--------------------------------------------\n",
      "france_out_mean_handle_custom_set \t validation score: \t 0.742  +/-  0.015\n",
      "--------------------------------------------\n",
      "italy_out_mean_handle_custom_set \t validation score: \t 0.832  +/-  0.002\n",
      "--------------------------------------------\n",
      "bulgaria_out_remove_handle_set_null \t validation score: \t 0.918  +/-  0.007\n",
      "--------------------------------------------\n",
      "finland_out_remove_handle_set_null \t validation score: \t 0.713  +/-  0.013\n",
      "--------------------------------------------\n",
      "france_out_remove_handle_set_null \t validation score: \t 0.732  +/-  0.027\n",
      "--------------------------------------------\n",
      "italy_out_remove_handle_set_null \t validation score: \t 0.803  +/-  0.012\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for data in datas:\n",
    "    rfr = RandomForestRegressor(max_depth=100, random_state = 42)\n",
    "    model = make_pipeline(scaler, rfr)\n",
    "    val_score = cross_val_score(model, data['X'], data['y'], cv=cv, n_jobs=-1, verbose=0)\n",
    "    data['val_score'] = val_score\n",
    "    print(data['name'], \"\\t validation score: \\t\", \"{:.3f}\".format(val_score.mean()), \" +/- \", \"{:.3f}\".format(val_score.std()))\n",
    "    print('--------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=4, shuffle=True, random_state = 42)\n",
    "scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:  3.3min remaining:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  3.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data validation score: \t 0.961  +/-  0.002\n",
      "\t test score: \t\t 0.962\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:  3.5min remaining:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  3.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data validation score: \t 0.960  +/-  0.002\n",
      "\t test score: \t\t 0.960\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:  4.0min remaining:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  4.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data validation score: \t 0.961  +/-  0.001\n",
      "\t test score: \t\t 0.961\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:  2.6min remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  2.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data validation score: \t 0.954  +/-  0.001\n",
      "\t test score: \t\t 0.959\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(max_depth=100, random_state = 42)\n",
    "model = make_pipeline(scaler, rfr)\n",
    "for X, y, region_id in zip(Xs, ys, region_ids):\n",
    "    val_score = cross_val_score(model, X, y, cv=cv, n_jobs=-1, verbose=0)\n",
    "    print(\"Validation score: \\t\", \"{:.3f}\".format(val_score.mean()), \" +/- \", \"{:.3f}\".format(val_score.std()))\n",
    "    print('--------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the only outliers handler that cause a meaningful score reduction is the removal of rows with outliers.\n",
    "The other techniques have similar scores, we choose to continue with *mean of closest point* since it performed slightly better\n",
    "than the other two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_closest_point = datas[0:4]\n",
    "X = X_closest_point\n",
    "y = y_closest_point\n",
    "X_train = np.vstack((datas[0]['X_train'], datas[1]['X_train'], datas[2]['X_train'], datas[3]['X_train']))\n",
    "y_train = np.concatenate((datas[0]['y_train'], datas[1]['y_train'], datas[2]['y_train'], datas[3]['y_train']))\n",
    "X_test = np.vstack((datas[0]['X_test'], datas[1]['X_test'], datas[2]['X_test'], datas[3]['X_test']))\n",
    "y_test = np.concatenate((datas[0]['y_test'], datas[1]['y_test'], datas[2]['y_test'], datas[3]['y_test']))\n",
    "data_all = {'name': 'Whole dataset', 'X': X, 'y': y, 'X_train': X_train, 'y_train': y_train, 'X_test': X_test, 'y_test': y_test}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_train_test(data, grid_search):\n",
    "    print(data['name'])\n",
    "    grid_search.fit(data['X_train'], data['y_train'])\n",
    "    print('\\tcross validation best score: \\t',  \"{:.3f}\".format(grid_search.best_score_))\n",
    "    print('\\tbest params: ', grid_search.best_params_)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    test_score = best_model.score(data['X_test'], data['y_test'])\n",
    "    print(\"\\tbest model test score: \\t\\t\", \"{:.3f}\".format(test_score))\n",
    "    print('--------------------------------------------')\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def model_train_test(data, model, cv):\n",
    "    print(data['name'])\n",
    "    val_score = cross_val_score(model, data['X_train'], data['y_train'], cv=cv, n_jobs=-1, verbose=0)\n",
    "    print('all scores:', val_score)\n",
    "    print(\"\\t validation score: \\t\", \"{:.3f}\".format(val_score.mean()), \" +/- \", \"{:.3f}\".format(val_score.std()*2))\n",
    "    model.fit(data['X_train'], data['y_train'])\n",
    "    test_score = model.score(data['X_test'], data['y_test'])\n",
    "    print(\"\\tbest model test score: \\t\\t\", \"{:.3f}\".format(test_score))\n",
    "    print('--------------------------------------------')\n",
    "    return model\n",
    "\n",
    "def apply_trained_model(datas, model):\n",
    "    for data in datas:\n",
    "        test_score = model.score(data['X_test'], data['y_test'])\n",
    "        print(data['name'], \"\\tbest all data model score: \\t\\t\", \"{:.3f}\".format(test_score))\n",
    "        print('--------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dtr__max_features': ['auto', 'sqrt'],\n",
       " 'dtr__criterion': ['mse', 'friedman_mse'],\n",
       " 'dtr__max_depth': [4, 8, 16, 32, None]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = ['auto', 'sqrt']\n",
    "criterion = ['mse', 'friedman_mse']\n",
    "max_depth = [4, 8, 16, 32, None]\n",
    "\n",
    "grid_params = {'dtr__max_features': max_features,\n",
    "              'dtr__criterion': criterion,\n",
    "              'dtr__max_depth': max_depth}\n",
    "grid_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------- Regional datas ------- \n",
      "\n",
      "france_out_closest_point_mean_handle_custom_set\n",
      "\tcross validation best score: \t 0.569\n",
      "\tbest params:  {'dtr__criterion': 'mse', 'dtr__max_depth': 8, 'dtr__max_features': 'auto'}\n",
      "\tbest model test score: \t\t 0.585\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\" ------- Regional datas ------- \\n\")\n",
    "dtr = DecisionTreeRegressor()\n",
    "model = Pipeline([('scaler', scaler), ('dtr', dtr)])\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = grid_params, \n",
    "                              cv = cv, n_jobs = -1, verbose = 0)\n",
    "\n",
    "for data in datas_closest_point:\n",
    "    grid_search_train_test(data, grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------- All datas ------- \n",
      "\n",
      "Whole dataset\n",
      "\tcross validation best score: \t 0.927\n",
      "\tbest params:  {'dtr__criterion': 'friedman_mse', 'dtr__max_depth': 16, 'dtr__max_features': 'auto'}\n",
      "\tbest model test score: \t\t 0.934\n",
      "--------------------------------------------\n",
      " ------- Best all estimator on regional data ------- \n",
      "\n",
      "france_out_closest_point_mean_handle_custom_set \tbest all data model score: \t\t 0.600\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n ------- All datas ------- \\n\")\n",
    "best_all_estimator = grid_search_train_test(data_all, grid_search)\n",
    "\n",
    "print(\" ------- Best all estimator on regional data ------- \\n\")\n",
    "apply_trained_model(datas_closest_point, best_all_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 200]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [20, 50, None]\n",
    "min_samples_split = [2, 5]\n",
    "min_samples_leaf = [1, 4]\n",
    "bootstrap = [False, True]\n",
    "\n",
    "grid_params = {'rfr__n_estimators': n_estimators,\n",
    "               'rfr__max_features': max_features,\n",
    "               'rfr__max_depth': max_depth,\n",
    "               #'rfr__min_samples_split': min_samples_split,\n",
    "               #'rfr__min_samples_leaf': min_samples_leaf,\n",
    "               #'rfr__bootstrap': bootstrap\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------- Regional datas ------- \n",
      "\n",
      "france_out_closest_point_mean_handle_custom_set\n",
      "\tcross validation best score: \t 0.734\n",
      "\tbest params:  {'rfr__max_depth': 20, 'rfr__max_features': 'sqrt', 'rfr__n_estimators': 200}\n",
      "\tbest model test score: \t\t 0.771\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\" ------- Regional datas ------- \\n\")\n",
    "rfr = RandomForestRegressor()\n",
    "model = Pipeline([('scaler', scaler), ('rfr', rfr)])\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = grid_params, \n",
    "                              cv = cv, n_jobs = -1, verbose = 0)\n",
    "\n",
    "for data in datas_closest_point:\n",
    "    grid_search_train_test(data, grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n ------- All datas ------- \\n\")\n",
    "best_all_estimator = grid_search_train_test(data_all, grid_search)\n",
    "\n",
    "print(\" ------- Best all estimator on regional data ------- \\n\")\n",
    "apply_trained_model(datas_closest_point, best_all_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------- Regional datas ------- \n",
      "\n",
      "bulgaria_out_closest_point_mean_handle_custom_set\n",
      "all scores: [0.6842919  0.653286   0.63819187 0.6732945 ]\n",
      "\t validation score: \t 0.662  +/-  0.036\n",
      "\tbest model test score: \t\t 0.689\n",
      "--------------------------------------------\n",
      "finland_out_closest_point_mean_handle_custom_set\n",
      "all scores: [0.14672251 0.15110454 0.13723825 0.1275094 ]\n",
      "\t validation score: \t 0.141  +/-  0.018\n",
      "\tbest model test score: \t\t 0.138\n",
      "--------------------------------------------\n",
      "france_out_closest_point_mean_handle_custom_set\n",
      "all scores: [-24.86678018   0.5304591    0.47770628   0.56657461]\n",
      "\t validation score: \t -5.823  +/-  21.990\n",
      "\tbest model test score: \t\t 0.601\n",
      "--------------------------------------------\n",
      "italy_out_closest_point_mean_handle_custom_set\n",
      "all scores: [0.51655417 0.53508659 0.51703452 0.53220658]\n",
      "\t validation score: \t 0.525  +/-  0.017\n",
      "\tbest model test score: \t\t 0.530\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\" ------- Regional datas ------- \\n\")\n",
    "lr = LinearRegression()\n",
    "model = Pipeline([('scaler', scaler), ('lr', lr)])\n",
    "\n",
    "for data in datas_closest_point:\n",
    "    model_train_test(data, model, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------- All datas ------- \n",
      "\n",
      "Whole dataset\n",
      "all scores: [0.76476679 0.77697724 0.77171997 0.77770604]\n",
      "\t validation score: \t 0.773  +/-  0.010\n",
      "\tbest model test score: \t\t 0.770\n",
      "--------------------------------------------\n",
      " ------- Best all estimator on regional data ------- \n",
      "\n",
      "bulgaria_out_closest_point_mean_handle_custom_set \tbest all data model score: \t\t 0.463\n",
      "--------------------------------------------\n",
      "finland_out_closest_point_mean_handle_custom_set \tbest all data model score: \t\t -0.168\n",
      "--------------------------------------------\n",
      "france_out_closest_point_mean_handle_custom_set \tbest all data model score: \t\t -0.894\n",
      "--------------------------------------------\n",
      "italy_out_closest_point_mean_handle_custom_set \tbest all data model score: \t\t 0.134\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n ------- All datas ------- \\n\")\n",
    "best_all_estimator = model_train_test(data_all, model, cv)\n",
    "\n",
    "print(\" ------- Best all estimator on regional data ------- \\n\")\n",
    "apply_trained_model(datas_closest_point, best_all_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svr__C': [0.1, 1, 10],\n",
       " 'svr__gamma': ['auto', 0.1, 0.01],\n",
       " 'svr__kernel': ['linear', 'rbf']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = [0.1, 1, 10]\n",
    "gamma = ['auto', 0.1, 0.01]\n",
    "kernel = ['linear', 'rbf']\n",
    "\n",
    "grid_params = {'svr__C': C,  \n",
    "              'svr__gamma': gamma, \n",
    "              'svr__kernel': kernel}  \n",
    "grid_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------- Regional datas ------- \n",
      "\n",
      "bulgaria_out_closest_point_mean_handle_custom_set\n",
      "\tcross validation best score: \t 0.818\n",
      "\tbest params:  {'svr__C': 10, 'svr__gamma': 0.1, 'svr__kernel': 'rbf'}\n",
      "\tbest model test score: \t\t 0.832\n",
      "--------------------------------------------\n",
      "finland_out_closest_point_mean_handle_custom_set\n",
      "\tcross validation best score: \t 0.112\n",
      "\tbest params:  {'svr__C': 10, 'svr__gamma': 0.1, 'svr__kernel': 'rbf'}\n",
      "\tbest model test score: \t\t 0.136\n",
      "--------------------------------------------\n",
      "france_out_closest_point_mean_handle_custom_set\n",
      "\tcross validation best score: \t 0.281\n",
      "\tbest params:  {'svr__C': 1, 'svr__gamma': 'auto', 'svr__kernel': 'linear'}\n",
      "\tbest model test score: \t\t 0.421\n",
      "--------------------------------------------\n",
      "italy_out_closest_point_mean_handle_custom_set\n",
      "\tcross validation best score: \t 0.528\n",
      "\tbest params:  {'svr__C': 10, 'svr__gamma': 0.1, 'svr__kernel': 'rbf'}\n",
      "\tbest model test score: \t\t 0.536\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\" ------- Regional datas ------- \\n\")\n",
    "svr = SVR()\n",
    "model = Pipeline([('scaler', scaler), ('svr', svr)])\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = grid_params, \n",
    "                              cv = cv, n_jobs = -1, verbose = 0)\n",
    "\n",
    "for data in datas_closest_point:\n",
    "    grid_search_train_test(data, grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------- All datas ------- \n",
      "\n",
      "Whole dataset\n",
      "\tcross validation best score: \t 0.876\n",
      "\tbest params:  {'svr__C': 10, 'svr__gamma': 0.1, 'svr__kernel': 'rbf'}\n",
      "\tbest model test score: \t\t 0.883\n",
      "--------------------------------------------\n",
      " ------- Best all estimator on regional data ------- \n",
      "\n",
      "bulgaria_out_closest_point_mean_handle_custom_set \tbest all data model score: \t\t 0.772\n",
      "--------------------------------------------\n",
      "finland_out_closest_point_mean_handle_custom_set \tbest all data model score: \t\t 0.116\n",
      "--------------------------------------------\n",
      "france_out_closest_point_mean_handle_custom_set \tbest all data model score: \t\t 0.191\n",
      "--------------------------------------------\n",
      "italy_out_closest_point_mean_handle_custom_set \tbest all data model score: \t\t 0.472\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n ------- All datas ------- \\n\")\n",
    "best_all_estimator = grid_search_train_test(data_all, grid_search)\n",
    "\n",
    "print(\" ------- Best all estimator on regional data ------- \\n\")\n",
    "apply_trained_model(datas_closest_point, best_all_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nn__solver': ['lbfgs'],\n",
       " 'nn__max_iter': [500, 1000],\n",
       " 'nn__alpha': [0.001, 0.0001, 1e-05],\n",
       " 'nn__hidden_layer_sizes': [(100, 50),\n",
       "  (46, 23),\n",
       "  (46, 100, 46),\n",
       "  (46, 100, 46, 20)]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = [500, 1000]\n",
    "alpha = [0.001, 0.0001, 0.00001]\n",
    "solver = ['lbfgs']\n",
    "hidden_layer_sizes = [(100, 50), (46, 23), (46, 100, 46), (46, 100, 46, 20)]\n",
    "\n",
    "grid_params = {'nn__solver': solver, \n",
    "               'nn__max_iter': max_iter,\n",
    "               'nn__alpha': alpha, \n",
    "               'nn__hidden_layer_sizes': hidden_layer_sizes\n",
    "              }\n",
    "grid_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------- Regional datas ------- \n",
      "\n",
      "bulgaria_out_closest_point_mean_handle_custom_set\n",
      "\tcross validation best score: \t 0.885\n",
      "\tbest params:  {'nn__alpha': 1e-05, 'nn__hidden_layer_sizes': (46, 100, 46, 20), 'nn__max_iter': 1000, 'nn__solver': 'lbfgs'}\n",
      "\tbest model test score: \t\t 0.894\n",
      "--------------------------------------------\n",
      "finland_out_closest_point_mean_handle_custom_set\n",
      "\tcross validation best score: \t 0.294\n",
      "\tbest params:  {'nn__alpha': 1e-05, 'nn__hidden_layer_sizes': (100, 50), 'nn__max_iter': 500, 'nn__solver': 'lbfgs'}\n",
      "\tbest model test score: \t\t 0.184\n",
      "--------------------------------------------\n",
      "france_out_closest_point_mean_handle_custom_set\n",
      "\tcross validation best score: \t 0.611\n",
      "\tbest params:  {'nn__alpha': 0.0001, 'nn__hidden_layer_sizes': (100, 50), 'nn__max_iter': 500, 'nn__solver': 'lbfgs'}\n",
      "\tbest model test score: \t\t 0.674\n",
      "--------------------------------------------\n",
      "italy_out_closest_point_mean_handle_custom_set\n",
      "\tcross validation best score: \t 0.643\n",
      "\tbest params:  {'nn__alpha': 0.0001, 'nn__hidden_layer_sizes': (46, 100, 46), 'nn__max_iter': 500, 'nn__solver': 'lbfgs'}\n",
      "\tbest model test score: \t\t 0.623\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\" ------- Regional datas ------- \\n\")\n",
    "nn = MLPRegressor()\n",
    "model = Pipeline([('scaler', scaler), ('nn', nn)])\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = grid_params, \n",
    "                              cv = cv, n_jobs = -1, verbose = 0)\n",
    "\n",
    "for data in datas_closest_point:\n",
    "    grid_search_train_test(data, grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------- All datas ------- \n",
      "\n",
      "Whole dataset\n",
      "\tcross validation best score: \t 0.907\n",
      "\tbest params:  {'nn__alpha': 1e-05, 'nn__hidden_layer_sizes': (46, 100, 46), 'nn__max_iter': 1000, 'nn__solver': 'lbfgs'}\n",
      "\tbest model test score: \t\t 0.909\n",
      "--------------------------------------------\n",
      " ------- Best all estimator on regional data ------- \n",
      "\n",
      "bulgaria_out_closest_point_mean_handle_custom_set \tbest all data model score: \t\t 0.843\n",
      "--------------------------------------------\n",
      "finland_out_closest_point_mean_handle_custom_set \tbest all data model score: \t\t 0.167\n",
      "--------------------------------------------\n",
      "france_out_closest_point_mean_handle_custom_set \tbest all data model score: \t\t 0.295\n",
      "--------------------------------------------\n",
      "italy_out_closest_point_mean_handle_custom_set \tbest all data model score: \t\t 0.577\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n ------- All datas ------- \\n\")\n",
    "best_all_estimator = grid_search_train_test(data_all, grid_search)\n",
    "\n",
    "print(\" ------- Best all estimator on regional data ------- \\n\")\n",
    "apply_trained_model(datas_closest_point, best_all_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave one region out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of finland_out_remove_handle_set_null score:  -26.166\n",
      "------------------------------\n",
      "Prediction of italy_out_closest_point_mean_handle_custom_set score:  -5.524\n",
      "------------------------------\n",
      "Prediction of france_out_closest_point_mean_handle_custom_set score:  -0.908\n",
      "------------------------------\n",
      "Prediction of bulgaria_out_closest_point_mean_handle_custom_set score:  -2.060\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "reg_idx = [0,1,2,3]\n",
    "comb = combinations(reg_idx, 3)\n",
    "\n",
    "for c in list(comb):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in c:\n",
    "        X_train.append(datas[i]['X'])\n",
    "        y_train.append(datas[i]['y'])\n",
    "        \n",
    "    X_train = np.vstack(X_train)\n",
    "    y_train = np.hstack(y_train)\n",
    "    \n",
    "    test_idx = list(set(reg_idx) - set(c))[0]\n",
    "   \n",
    "    X_test = datas[test_idx]['X']\n",
    "    y_test = datas[test_idx]['y']\n",
    "    \n",
    "    rfr = RandomForestRegressor(random_state = 42)\n",
    "    model = make_pipeline(scaler, rfr)\n",
    "    model.fit(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    print(\"Prediction of\", datas[test_idx]['name'], \"score: \", \"{:.3f}\".format(test_score))\n",
    "    print('------------------------------')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
