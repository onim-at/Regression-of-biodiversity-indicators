{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression on biodiversity index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to test different models on our dataset, trying to get a better results using a grid search and the testing the models on a dataset of a different region.\n",
    "\n",
    "For each model we're going to use a RandomizedSearchCV to narrow our parameters research and the the GridSearchCV to find the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_label = 'habitat_richness'\n",
    "folder = \"../Dataset\"\n",
    "\n",
    "regions = ['france', 'finland']\n",
    "\n",
    "file_france = \"/france_yearavg_out_mean.csv\"\n",
    "file_finland =  \"/finland_yearavg_out_mean.csv\"\n",
    "\n",
    "df_france = pd.read_csv(folder + file_france, index_col=['longitude', 'latitude'])\n",
    "df_finland = pd.read_csv(folder + file_finland, index_col=['longitude', 'latitude'])\n",
    "\n",
    "df_france = df_france.dropna(axis=1)\n",
    "df_finland = df_finland.dropna(axis=1)\n",
    "\n",
    "dfs = [df_france, df_finland]\n",
    "\n",
    "ys = [df[regression_label].values.reshape(-1,1) for df in dfs]\n",
    "Xs = [df.drop(columns=[regression_label]).values for df in dfs]\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "X_all = np.vstack(Xs)\n",
    "y_all = np.vstack(ys)\n",
    "\n",
    "for X, y, region in zip(Xs, ys, regions):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    data[region] = {'X': X, 'y': y, 'X_train': X_train, 'y_train': y_train, 'X_test': X_test, 'y_test': y_test}\n",
    "\n",
    "X_train_all = np.vstack([data[region]['X_train'] for region in data])    \n",
    "y_train_all = np.vstack([data[region]['y_train'] for region in data])     \n",
    "X_test_all = np.vstack([data[region]['X_test'] for region in data])    \n",
    "y_test_all = np.vstack([data[region]['y_test'] for region in data])    \n",
    "\n",
    "# Normalize the data\n",
    "X_scaler = preprocessing.MinMaxScaler()\n",
    "y_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Test values have to be normalized with the training mean and std\n",
    "X_scaler.fit(X_train_all)\n",
    "y_scaler.fit(y_train_all.reshape(-1, 1))\n",
    "\n",
    "for region in data:\n",
    "    data[region]['X'] = X_scaler.transform(data[region]['X'])\n",
    "    data[region]['X_train'] = X_scaler.transform(data[region]['X_train'])\n",
    "    data[region]['X_test'] = X_scaler.transform(data[region]['X_test'])\n",
    "    data[region]['y'] = y_scaler.transform(data[region]['y'])\n",
    "    data[region]['y_train'] = y_scaler.transform(data[region]['y_train'])\n",
    "    data[region]['y_test'] = y_scaler.transform(data[region]['y_test'])\n",
    "\n",
    "\n",
    "X_train_all = X_scaler.transform(X_train_all)\n",
    "X_test_all = X_scaler.transform(X_test_all)\n",
    "\n",
    "y_train_all = y_scaler.transform(y_train_all.reshape(-1, 1)).ravel()\n",
    "y_test_all = y_scaler.transform(y_test_all.reshape(-1, 1)).ravel()\n",
    "y = y_scaler.transform(y.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'france'\n",
    "\n",
    "X_train = data[region]['X_train']\n",
    "y_train = data[region]['y_train']\n",
    "X_test = data[region]['X_test']\n",
    "y_test = data[region]['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [50, 100, 150, 200],\n",
       " 'max_features': [None, 'sqrt'],\n",
       " 'max_depth': [10, 40, 70, 100, None],\n",
       " 'min_samples_split': [2, 5, 10],\n",
       " 'min_samples_leaf': [1, 2, 4],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 200, num = 4)]\n",
    "max_features = [None, 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 100, num = 4)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-35711da132e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# Instantiate the grid search model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m grid_search = GridSearchCV(estimator = rf, param_grid = random_grid, \n\u001b[0m\u001b[0;32m      3\u001b[0m                           cv = cv, n_jobs = -1, verbose = 5)\n\u001b[0;32m      4\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random_grid' is not defined"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor()# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = cv, n_jobs = -1, verbose = 5)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-1d51dbe7ac06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-103-c1ff8b144da4>:9: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  base_model.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model score:  0.716239712324147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-103-c1ff8b144da4>:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  best_grid.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best grid search:  0.7183231662135094\n"
     ]
    }
   ],
   "source": [
    "best_params = {'bootstrap': False,\n",
    " 'max_depth': 70,\n",
    " 'max_features': 'sqrt',\n",
    " 'min_samples_leaf': 4,\n",
    " 'min_samples_split': 10,\n",
    " 'n_estimators': 150}\n",
    "\n",
    "base_model = RandomForestRegressor(random_state = 42)\n",
    "base_model.fit(X_train, y_train.ravel())\n",
    "print(\"Base model score: \", base_model.score(X_test, y_test.ravel()))\n",
    "best_grid = RandomForestRegressor(**best_params)\n",
    "best_grid.fit(X_train, y_train.ravel())\n",
    "print(\"Best grid search: \", best_grid.score(X_test, y_test.ravel()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using finland as train and france as test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  -3.3214950219022796\n"
     ]
    }
   ],
   "source": [
    "X_train = data['finland']['X']\n",
    "y_train = data['finland']['y']\n",
    "X_test = data['france']['X']\n",
    "y_test = data['france']['y']\n",
    "\n",
    "rfr = RandomForestRegressor(random_state = 42)\n",
    "rfr.fit(X_train, y_train.ravel())\n",
    "print(\"score: \", rfr.score(X_test, y_test.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(random_state = 42)\n",
    "rfr.fit(X_train_all, y_train_all.ravel())\n",
    "print(\"score: \", rfr.score(X_test_all, y_test_all.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=True),\n",
       "             estimator=MLPRegressor(random_state=42), n_jobs=-1,\n",
       "             param_grid={'activation': ['logistic', 'tanh', 'relu'],\n",
       "                         'hidden_layer_sizes': [(100, 50), (100, 100, 50),\n",
       "                                                (50, 100, 50), (200, 100, 50)],\n",
       "                         'solver': ['sgd', 'adam']},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_sizes=[(100, 50), (100, 100, 50), (50, 100, 50), (200, 100, 50)]\n",
    "activation=['logistic', 'tanh', 'relu']\n",
    "solver=['sgd', 'adam']\n",
    "\n",
    "param_grid = {'hidden_layer_sizes': hidden_layer_sizes,\n",
    "               'activation': activation,\n",
    "             'solver': solver}\n",
    "\n",
    "nn = MLPRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator = nn, param_grid = param_grid, \n",
    "                          cv = cv, n_jobs = -1, verbose = 5)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model score:  0.6439338791160267\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-f18d250e1e26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Base model score: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best grid search: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "regr = MLPRegressor(hidden_layer_sizes=(100, 50), random_state=42).fit(X_train, y_train)\n",
    "print(\"Base model score: \", regr.score(X_test, y_test))\n",
    "\n",
    "best = grid_search.best_estimator_\n",
    "best.fit(X_train, y_train)\n",
    "print(\"Best grid search: \", best.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  -90.58659471535638\n"
     ]
    }
   ],
   "source": [
    "X_train = data['finland']['X']\n",
    "y_train = data['finland']['y']\n",
    "X_test = data['france']['X']\n",
    "y_test = data['france']['y']\n",
    "\n",
    "regr = MLPRegressor(hidden_layer_sizes=(100, 50), random_state=42).fit(X_train, y_train.ravel())\n",
    "print(\"score: \", regr.score(X_test, y_test.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
